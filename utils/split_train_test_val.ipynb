{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import os\n",
    "from collections import defaultdict\n",
    "import numpy as np \n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_dir = \"../annotations\"\n",
    "annotations_filename = \"annotations_full.json\"\n",
    "annotations_filepath = os.path.join(annotations_dir, annotations_filename)\n",
    "annotations = json.load(open(annotations_filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['categories', 'images', 'segmentation_images', 'input_oracle_annotations', 'annotations', 'phrase_annotations'])\n"
     ]
    }
   ],
   "source": [
    "print(annotations.keys())\n",
    "categories = annotations[\"categories\"]\n",
    "images = annotations[\"images\"]\n",
    "det_annotations = annotations[\"annotations\"]\n",
    "oracle_annotations = annotations[\"input_oracle_annotations\"]\n",
    "segmentation_images = annotations[\"segmentation_images\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_anns_map = defaultdict(list)\n",
    "oracle_anns_map = defaultdict(list)\n",
    "\n",
    "for ann in det_annotations:\n",
    "    det_anns_map[ann[\"image_id\"]].append(ann)\n",
    "\n",
    "for ann in oracle_annotations:\n",
    "    oracle_anns_map[ann[\"image_id\"]].append(ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotations = {}\n",
    "train_annotations[\"categories\"] = categories\n",
    "train_annotations[\"images\"] = []\n",
    "train_annotations[\"annotations\"] = []\n",
    "train_annotations[\"input_oracle_annotations\"] = []\n",
    "train_annotations[\"segmentation_images\"] = []\n",
    "\n",
    "val_annotations = {}\n",
    "val_annotations[\"categories\"] = categories\n",
    "val_annotations[\"images\"] = []\n",
    "val_annotations[\"annotations\"] = []\n",
    "val_annotations[\"input_oracle_annotations\"] = []\n",
    "val_annotations[\"segmentation_images\"] = []\n",
    "\n",
    "test_annotations = {}\n",
    "test_annotations[\"categories\"] = categories\n",
    "test_annotations[\"images\"] = []\n",
    "test_annotations[\"annotations\"] = []\n",
    "test_annotations[\"input_oracle_annotations\"] = []\n",
    "test_annotations[\"segmentation_images\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\n",
      "19999\n",
      "29999\n",
      "39999\n",
      "49999\n",
      "59999\n",
      "69999\n",
      "79999\n",
      "89999\n",
      "99999\n",
      "109999\n",
      "119999\n",
      "129999\n",
      "139999\n",
      "149999\n",
      "159999\n",
      "169999\n",
      "179999\n",
      "189999\n",
      "199999\n",
      "209999\n",
      "219999\n",
      "229999\n",
      "239999\n",
      "249999\n"
     ]
    }
   ],
   "source": [
    "# randomly shuffle a list \n",
    "n_determiners = 25 \n",
    "n_samples_per_determiner = 10000\n",
    "\n",
    "train = 0.7 \n",
    "val = 0.1 \n",
    "test = 0.2\n",
    "\n",
    "for i in range(n_determiners): \n",
    "    # generate a list of random indexes from 1 to 10000\n",
    "    idxs = [j for j in range(i*n_samples_per_determiner, (i+1)*n_samples_per_determiner)]\n",
    "    print(idxs[-1])\n",
    "    np.random.shuffle(idxs)\n",
    "    n_train = int(train * n_samples_per_determiner)\n",
    "    n_val = int(val * n_samples_per_determiner)\n",
    "    n_test = n_samples_per_determiner - n_train - n_val\n",
    "\n",
    "    train_idxs = idxs[:n_train]\n",
    "    val_idxs = idxs[n_train:n_train+n_val]\n",
    "    test_idxs = idxs[n_train+n_val:]\n",
    "\n",
    "    for idx in train_idxs:\n",
    "        image = images[idx]\n",
    "        train_annotations[\"images\"].append(image)\n",
    "        train_annotations[\"annotations\"].extend(det_anns_map[image[\"id\"]])\n",
    "        train_annotations[\"input_oracle_annotations\"].extend(oracle_anns_map[image[\"id\"]])\n",
    "\n",
    "    for idx in val_idxs:\n",
    "        image = images[idx]\n",
    "        val_annotations[\"images\"].append(image)\n",
    "        val_annotations[\"annotations\"].extend(det_anns_map[image[\"id\"]])\n",
    "        val_annotations[\"input_oracle_annotations\"].extend(oracle_anns_map[image[\"id\"]])\n",
    "\n",
    "    for idx in test_idxs:\n",
    "        image = images[idx]\n",
    "        test_annotations[\"images\"].append(image)\n",
    "        test_annotations[\"annotations\"].extend(det_anns_map[image[\"id\"]])\n",
    "        test_annotations[\"input_oracle_annotations\"].extend(oracle_anns_map[image[\"id\"]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train annotations:  175000\n",
      "Length of val annotations:  25000\n",
      "Length of test annotations:  50000\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of train annotations: \", len(train_annotations[\"images\"]))\n",
    "print(\"Length of val annotations: \", len(val_annotations[\"images\"]))\n",
    "print(\"Length of test annotations: \", len(test_annotations[\"images\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'a': 7000, 'an': 7000, 'all': 7000, 'any': 7000, 'every': 7000, 'my': 7000, 'your': 7000, 'this': 7000, 'that': 7000, 'these': 7000, 'those': 7000, 'some': 7000, 'many': 7000, 'few': 7000, 'both': 7000, 'neither': 7000, 'little': 7000, 'much': 7000, 'either': 7000, 'our': 7000, 'no': 7000, 'the': 7000, 'half': 7000, 'several': 7000, 'each': 7000})\n"
     ]
    }
   ],
   "source": [
    "det_counts = defaultdict(int)\n",
    "\n",
    "for images in train_annotations[\"images\"]:\n",
    "    caption = images[\"caption\"]\n",
    "    det = caption.split(\" \")[0]\n",
    "    det_counts[det] += 1\n",
    "\n",
    "print(det_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the annotations\n",
    "\n",
    "train_annotations_filename = \"annotations_train.json\"\n",
    "train_annotations_filepath = os.path.join(annotations_dir, train_annotations_filename)\n",
    "json.dump(train_annotations, open(train_annotations_filepath, \"w\"))\n",
    "\n",
    "val_annotations_filename = \"annotations_val.json\"\n",
    "val_annotations_filepath = os.path.join(annotations_dir, val_annotations_filename)\n",
    "json.dump(val_annotations, open(val_annotations_filepath, \"w\"))\n",
    "\n",
    "test_annotations_filename = \"annotations_test.json\"\n",
    "test_annotations_filepath = os.path.join(annotations_dir, test_annotations_filename)\n",
    "json.dump(test_annotations, open(test_annotations_filepath, \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98f310addaf7dac00cd5965e6c1c6cb4dc304674e0e6e4d0010a991e9aec678e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
